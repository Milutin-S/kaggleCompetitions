{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory, so we don't download the same dataset twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Studen\\\\Documents\\\\vscode_projects\\\\kaggleCompetitions\\\\Digit_Recognizer\\\\VAE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Studen\\\\Documents\\\\vscode_projects\\\\kaggleCompetitions\\\\Digit_Recognizer\\\\scripts'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_working_dir = os.path.dirname(working_dir)\n",
    "os.chdir(os.path.join(new_working_dir, \"scripts\"))\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"C:/Users/Studen/Documents/vscode_projects/kaggleCompetitions/Digit_Recognizer/Dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input img -> Hidden dim -> mean, std -> Paramertication Trick -> Decoder -> Output img\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim=200, z_dim=20) -> None:\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.img_2hid = nn.Linear(input_dim, h_dim)\n",
    "        self.hid_2mu = nn.Linear(h_dim, z_dim)\n",
    "        self.hid_2sigma = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.z_2hid = nn.Linear(z_dim, h_dim)\n",
    "        self.hid_2img = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.tanh = nn.Tanh()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # q_phi(z|x)\n",
    "        h = self.relu(self.img_2hid(x))\n",
    "        mu = self.hid_2mu(h)\n",
    "        sigma = self.hid_2sigma(h)\n",
    "        return mu, sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        # p_theta(x|z)\n",
    "        h = self.relu(self.z_2hid(z))\n",
    "        img = self.sigmoid(self.hid_2img(h))\n",
    "        return img\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_reparametrized = mu + sigma*epsilon\n",
    "        x_reconstructed = self.decode(z_reparametrized)\n",
    "        return x_reconstructed, mu, sigma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 784])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([4, 20])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 28*28)\n",
    "vae = VariationalAutoEncoder(input_dim=784)\n",
    "x_reconstructed, mu, sigma = vae(x)\n",
    "print(x_reconstructed.shape)\n",
    "print(mu.shape)\n",
    "print(sigma.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scripts.globals import *\n",
    "from scripts.dataset_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current working device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Current working device: {device}\")\n",
    "INPUT_DIM = 784\n",
    "H_DIM = 200\n",
    "Z_DIM = 20\n",
    "NUM_EPOCH = 30 # 100 \n",
    "BATCH_SIZE = 64\n",
    "LR_RATE = 3e-4 # Karpathy constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DigitDataset(data_path=\"C:/Users/Studen/Documents/vscode_projects/kaggleCompetitions/Digit_Recognizer/Dataset/train.csv\", type=\"train\")\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Minimum data value: 0.0, Maximum data value: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(f\"[INFO] Minimum data value: {torch.min(images)}, Maximum data value: {torch.max(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "model = VariationalAutoEncoder(INPUT_DIM, H_DIM, Z_DIM).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "loss_fn = nn.BCELoss(reduction=\"sum\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "657it [00:07, 82.46it/s, loss=3.06e+3] \n",
      "657it [00:07, 92.59it/s, loss=2.88e+3] \n",
      "657it [00:07, 84.89it/s, loss=2.52e+3]\n",
      "657it [00:07, 83.10it/s, loss=2.25e+3]\n",
      "657it [00:07, 83.09it/s, loss=2.07e+3]\n",
      "657it [00:07, 83.21it/s, loss=2.3e+3] \n",
      "657it [00:07, 82.85it/s, loss=2.29e+3]\n",
      "657it [00:07, 83.12it/s, loss=2.38e+3]\n",
      "657it [00:07, 83.12it/s, loss=2.56e+3]\n",
      "657it [00:07, 83.14it/s, loss=2.15e+3]\n",
      "657it [00:07, 83.02it/s, loss=2.23e+3]\n",
      "657it [00:07, 83.27it/s, loss=2.35e+3]\n",
      "657it [00:07, 83.06it/s, loss=2.47e+3]\n",
      "657it [00:07, 82.69it/s, loss=2.19e+3]\n",
      "657it [00:07, 83.16it/s, loss=2.1e+3] \n",
      "657it [00:07, 83.04it/s, loss=2.16e+3]\n",
      "657it [00:07, 82.90it/s, loss=2.32e+3]\n",
      "657it [00:07, 82.40it/s, loss=2.05e+3]\n",
      "657it [00:07, 82.63it/s, loss=2.24e+3]\n",
      "657it [00:07, 83.29it/s, loss=2.32e+3]\n",
      "657it [00:07, 83.23it/s, loss=1.86e+3]\n",
      "657it [00:07, 83.05it/s, loss=2.14e+3]\n",
      "657it [00:07, 82.91it/s, loss=2.26e+3]\n",
      "657it [00:07, 83.23it/s, loss=2.06e+3]\n",
      "657it [00:07, 82.89it/s, loss=2.08e+3]\n",
      "657it [00:07, 82.93it/s, loss=1.79e+3]\n",
      "657it [00:07, 83.40it/s, loss=2.36e+3]\n",
      "657it [00:07, 83.32it/s, loss=2.02e+3]\n",
      "657it [00:07, 83.14it/s, loss=2.06e+3]\n",
      "657it [00:07, 83.34it/s, loss=1.97e+3]\n"
     ]
    }
   ],
   "source": [
    "best_loss = None\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    loop = tqdm(enumerate(train_loader))\n",
    "    for i, (x, _) in loop:\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(x.shape[0], INPUT_DIM)\n",
    "        x_reconstructed, mu, sigma = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        reconstructed_loss = loss_fn(x_reconstructed, x)\n",
    "        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "\n",
    "        # Backprop\n",
    "        loss = reconstructed_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        if best_loss is None or loss.item() < best_loss:\n",
    "            best_loss = loss.intem()\n",
    "            torch.save(\n",
    "                model.state_dict(), f\"C:/Users/Studen/Documents/vscode_projects/kaggleCompetitions/Digit_Recognizer/VAE/best_weights.pth\"\n",
    "            )\n",
    "            tqdm.write(f\"    Best accuracy in {epoch} epoch saved. âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 1\n"
     ]
    }
   ],
   "source": [
    "for index in range(dataset.__len__()):\n",
    "    data, label = dataset.__getitem__(index)\n",
    "    print(data.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")\n",
    "def create_new_data(num_examples=1, out_path:Path=Path(\"C:/Users/Studen/Documents/vscode_projects/kaggleCompetitions/Digit_Recognizer/Dataset\")):\n",
    "    df_vae = pd.DataFrame(columns=df_train.columns)\n",
    "    print(f\"[INFO] Shape of one row from existing data: {df_train.iloc[0].shape}\")\n",
    "    encoding_digit = []\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    for index in range(dataset.__len__()):\n",
    "        data, label = dataset.__getitem__(index)\n",
    "        # print(data.shape, label)\n",
    "        with torch.no_grad():\n",
    "            mu, sigma = model.encode(data.view(1, 784))\n",
    "    #     encoding_digit.append((mu, sigma))\n",
    "    \n",
    "    # mu, sigma = encoding_digit[digit]\n",
    "        for example in range(num_examples):\n",
    "            epsilon = torch.randn_like(sigma)\n",
    "            z = mu + sigma * epsilon\n",
    "            out = model.decode(z)\n",
    "            out = out.detach().numpy()\n",
    "            scaled_out = (out * 255).astype(np.uint8)\n",
    "            new_arr = np.insert(scaled_out, 0, label, axis=1)\n",
    "            # print(f\"[INFO] Shape of output: {out.shape}\")\n",
    "            # print(f\"[INFO] Shape of extended with label: {new_arr.shape}\")\n",
    "            # print(f\"[INFO] Real label: {label}\")\n",
    "            # print(f\"[INFO] Added label: {new_arr[0][0]}\")\n",
    "            # print(f\"[INFO] Min value: {np.min(new_arr)}, max value: {np.max(new_arr)}\")\n",
    "            new_arr = new_arr.squeeze(axis=0)\n",
    "            # print(f\"[INFO] Shape of extended with label after squeeze: {new_arr.shape}\")\n",
    "            df_vae.loc[len(df_vae)] = new_arr\n",
    "        # print(df_vae.shape)\n",
    "    return df_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Shape of one row from existing data: (785,)\n",
      "[INFO] Shape of output: (1, 784)\n",
      "[INFO] Shape of extended with label: (1, 785)\n",
      "[INFO] Real label: 1\n",
      "[INFO] Added label: 1\n",
      "[INFO] Min value: 0, max value: 252\n",
      "[INFO] Shape of extended with label after squeeze: (785,)\n",
      "(1, 785)\n"
     ]
    }
   ],
   "source": [
    "df_vae = create_new_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")\n",
    "def inference(digit, num_examples=1, out_path:Path=Path(\"./VAE_gen_examples\")):\n",
    "    \"\"\"\n",
    "    Generates (num_exmaples) of a particular digit.\n",
    "    Specifically we extract an exmaple of eaxh digit, \n",
    "    then after we have mu, sigma representation for \n",
    "    each digit we can sample from that.\n",
    "\n",
    "    After we sample we can run the decoder part of the VAE and generate examples.\n",
    "    \"\"\"\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "    images = []\n",
    "    idx = 0\n",
    "    for x, y in dataset:\n",
    "        if y == idx:\n",
    "            images.append(x)\n",
    "            idx += 1\n",
    "        if idx == 10:\n",
    "            break\n",
    "\n",
    "    encoding_digit = []\n",
    "    for d in range(10):\n",
    "        with torch.no_grad():\n",
    "            mu, sigma = model.encode(images[d]. view(1, 784))\n",
    "        encoding_digit.append((mu, sigma))\n",
    "    \n",
    "    mu, sigma = encoding_digit[digit]\n",
    "    for example in range(num_examples):\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        out = model.decode(z)\n",
    "        out = out.view(-1, 1, 28, 28)\n",
    "        save_image(out, out_path / f\"generated_{digit}_ex{example}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    inference(idx, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
